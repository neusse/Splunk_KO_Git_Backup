{
	"allow_skew": "0",
	"author": "nobody",
	"cron_schedule": "",
	"defer_scheduled_searchable_idxc": "0",
	"description": "Report only? Yes. This report is an attempt to use the Splunk audit logs to generate summary statistics on what indexes were accessed and the period of time they were accessed over. There is a lot of complexity here as the audit logs make this task very challenging. This version relates to entries where either index names are specified with wildcards or no index is specified, an additional report "SearchHeadLevel - Search Queries summary exact match" also exists to perform this same function where an index=<indexname> is specified. This report requires "SearchHeadLevel - Index access list by user" and "SearchHeadLevel - Macro report". Also note that you need to remove the comment around the lookup within the search...this report works on Splunk 8.0 or newer or 7.3 with some modification. Requires the splunkadmins_macros and splunkadmins_indexes_per_role lookup files to exist. Note pre Splunk 8.0 you will need to replace splunkadmins_audit_logs_macro_sub_v8 with splunkadmins_audit_logs_macro_sub. Note that this search utilises the streamfilterwildcard custom search command included in the TA-Alerts for SplunkAdmins application on SplunkBase (or github)",
	"disabled": "0",
	"dispatch.allow_partial_results": "1",
	"dispatch.auto_cancel": "0",
	"dispatch.auto_pause": "0",
	"dispatch.buckets": "0",
	"dispatch.earliest_time": "-1h",
	"dispatch.index_earliest": "",
	"dispatch.index_latest": "",
	"dispatch.indexedRealtime": "",
	"dispatch.indexedRealtimeMinSpan": "",
	"dispatch.indexedRealtimeOffset": "",
	"dispatch.latest_time": "now",
	"dispatch.lookups": "1",
	"dispatch.max_count": "500000",
	"dispatch.max_time": "0",
	"dispatch.rate_limit_retry": "0",
	"dispatch.reduce_freq": "10",
	"dispatch.rt_backfill": "0",
	"dispatch.rt_maximum_span": "",
	"dispatch.sample_ratio": "1",
	"dispatch.spawn_process": "1",
	"dispatch.time_format": "%FT%T.%Q%:z",
	"dispatch.ttl": "2p",
	"dispatchAs": "owner",
	"eai:acl.app": "SplunkAdmins",
	"eai:acl.can_change_perms": "1",
	"eai:acl.can_list": "1",
	"eai:acl.can_share_app": "1",
	"eai:acl.can_share_global": "1",
	"eai:acl.can_share_user": "0",
	"eai:acl.can_write": "1",
	"eai:acl.modifiable": "1",
	"eai:acl.owner": "nobody",
	"eai:acl.perms.read": "['admin', 'sc_admin']",
	"eai:acl.perms.write": "['admin', 'sc_admin']",
	"eai:acl.removable": "0",
	"eai:acl.sharing": "app",
	"embed.enabled": "0",
	"is_scheduled": "0",
	"is_visible": "1",
	"max_concurrent": "1",
	"precalculate_required_fields_for_alerts": "1",
	"published": "",
	"realtime_schedule": "1",
	"request.ui_dispatch_app": "SplunkAdmins",
	"request.ui_dispatch_view": "search",
	"restart_on_searchpeer_add": "1",
	"run_n_times": "0",
	"run_on_startup": "0",
	"schedule_as": "auto",
	"schedule_priority": "default",
	"schedule_window": "0",
	"skip_scheduled_realtime_idxc": "0",
	"splunk_server": "TheNeusse",
	"target": "saved/searches",
	"title": "SearchHeadLevel - Search Queries summary non-exact match",
	"updated": "1969-12-31T16:00:00-08:00",
	"vsid": "",
	"workload_pool": "",
	"search": 
| multisearch 
    [ search `comment("Last modified 2022-02-14 Attempt to extract out which indexes are accessed per search query by any search and compute statistics on them. The multisearch is only required if you want to capture sub-searches from join, append or similar, these require a bit more work so that's why the multisearch is there, in fact anything containing one of those keywords is dealt with in the second search, not this one...")` 
    `comment("Note that the regexes need more work, for now, limits.conf [rex] match_limit = 1000000 is my workaround (main issue is the union/set/multisearch rex)")` 
        index=_audit "info=completed" search_id!="'SummaryDirector_*" search_id!="'rsa_*" search_id!="'RemoteStorageRetrieveBuckets_*" scan_count>0 
    | rex "(?s), search='(?P<search>.*)\]$" 
    | rex "(?s)^(?:[^'\n]*'){4},\s+\w+='(?P<search>[\s\S]+)'\]($|\[[^\]]+\]$)" 
    | rex field=search mode=sed "s/```.*?```/ /g" 
    | eval search=if(substr(search,len(search),len(search)-1)=="'",substr(search,0,len(search)-1),search) 
    | eval search_id=replace(search_id,"'","") 
    | `search_type_from_sid(search_id)` 
    | `base64decode(base64appname)` 
    | eval app3="N/A" 
    | eval app_name=coalesce(app,base64appname,app3) 
    | fillnull app_name value="*" 
    | eval splunk_server = `splunkadmins_splunk_server_name` 
    | search `comment("Replace macros, but then replace datamodels, then tags, then eventtypes, but what if the eventtype refers to an eventtype? Or tag? Or more macros? This isn't perfect so just substitute a hope for the best. IndexerLevel - RemoteSearches Indexes Stats doesn't have all these issues so it may be safer to see what happens at indexing tier...")` 
    | `splunkadmins_audit_logs_macro_sub_v8` 
    | `splunkadmins_audit_logs_macro_sub_v8` 
    | regex search="^\s*(\|?)\s*(search|tstats|mstats|mcatalog|mutlisearch|union|set|summarize|datamodel|from\s*:?\s*datamodel|datamodelsimple)\s+" 
    | regex search!="\|\s*(append|union|multisearch|set|appendcols|appendpipe|join|map)" 
    | `splunkadmins_audit_logs_datamodel_sub` 
    | `splunkadmins_audit_logs_tags_sub` 
    | `splunkadmins_audit_logs_eventtypes_sub` 
    | `splunkadmins_audit_logs_eventtypes_sub` 
    | `splunkadmins_audit_logs_tags_sub` 
    | `splunkadmins_audit_logs_macro_sub_v8` 
    | `splunkadmins_audit_logs_macro_sub_v8` 
    | rex field=search mode=sed "s/```.*?```/ /g" 
    | rex field=search "(?s)^(?P<prepipe>\s*\|?([^\|]+))" ] 
    [ search `comment("Attempt to extract out which indexes are accessed per search query by any search and compute statistics on them. This search works on searches with an append/multisearch or other command that has a slightly different regex requirement. Note had to nomv the multivalued field before concatenation or it sliently disappeared!")` 
        index=_audit "info=completed" search_id!="'SummaryDirector_*" search_id!="'rsa_*" search_id!="'RemoteStorageRetrieveBuckets_*" scan_count>0 
    | rex "(?s), search='(?P<search>.*)\]$" 
    | rex "(?s)^(?:[^'\n]*'){4},\s+\w+='(?P<search>[\s\S]+)'\]($|\[[^\]]+\]$)" 
    | rex field=search mode=sed "s/```.*?```/ /g" 
    | eval search=if(substr(search,len(search),len(search)-1)=="'",substr(search,0,len(search)-1),search) 
    | eval search_id=replace(search_id,"'","") 
    | `search_type_from_sid(search_id)` 
    | `base64decode(base64appname)` 
    | eval app3="N/A" 
    | eval app_name=coalesce(app,base64appname,app3) 
    | eval splunk_server = `splunkadmins_splunk_server_name` 
    | fillnull app_name value="*" 
    | search `comment("Replace macros, but then replace datamodels, then tags, then eventtypes, but what if the eventtype refers to an eventtype? Or tag? Or more macros? This isn't perfect so just substitute a hope for the best. IndexerLevel - RemoteSearches Indexes Stats doesn't have all these issues so it may be safer to see what happens at indexing tier...")` 
    | `splunkadmins_audit_logs_macro_sub_v8` 
    | `splunkadmins_audit_logs_macro_sub_v8` 
    | regex search="\|\s*(append|union|multisearch|set|appendcols|appendpipe|join|map)" 
    | `splunkadmins_audit_logs_datamodel_sub` 
    | `splunkadmins_audit_logs_tags_sub` 
    | `splunkadmins_audit_logs_eventtypes_sub` 
    | `splunkadmins_audit_logs_eventtypes_sub` 
    | `splunkadmins_audit_logs_tags_sub` 
    | `splunkadmins_audit_logs_macro_sub_v8` 
    | `splunkadmins_audit_logs_macro_sub_v8` 
    | rex field=search mode=sed "s/```.*?```/ /g" 
    | rex field=search max_match=50 "(?s)\|?\s*(append|appendcols|appendpipe|map|union)\s+\[(?P<subsearch>.*?)\]\s*(\||$)" 
    | rex field=search max_match=50 "(?s)\|?\s*(join)\s+.*?\[(?P<subsearch>.*?)\]\s*(\||$)" 
    | rex field=search max_match=50 "(?s)\|?\s*(union|set|multisearch)\s+(?P<part1>\[.*?\](\s*\[.*?\])+\s*(`[^`]+`\s*)*(\||$))" 
    | rex field=part1 max_match=50 "(?s).*?\[(?P<subsearch>.*?)\]\s*(\||$|)" 
    | rex field=search max_match=50 "(?s)\|?\s*(map)\s+(maxsearches\s*=\s*\d+)?\s*search\s*=\s*\"(?P<subsearch>.*?)\"\s*(\||$)" 
    | rex field=search "^(?P<prepipe>\s*\|?([^\|]+))" 
    | rex field=subsearch "(?s)^\s*\|?(?P<prepipe_subsearch>([^\|]+))" 
    | nomv prepipe_subsearch 
    | eval prepipe = prepipe . " " . prepipe_subsearch ] 
| eval search=prepipe 
| search `comment("The (index=* OR index=_*) index=<specific index> is a common use case for enterprise security, also some individuals like doing a similar trick so remove the index=*... as this is not a wildcard index search")` 
| rex field=search "(?P<esstylewildcard>\(\s*index=\*\s+OR\s+index=_\*\s*\))" 
| rex mode=sed field=search "s/search index=\s*\S+\s+index\s*=/search index=/g" 
| search `comment("Extract out index= or index IN (a,b,c) but avoid NOT index in (...) and NOT index=... and also NOT (...anything) statements")` 
| rex field=search "(?s)(NOT\s+index(\s*=\s*|::)[^ ]+)|(NOT\s+\([^\)]+\))|(index(\s*=\s*|::)\"?(?P<indexregex>[\*A-Za-z0-9-_]+))" max_match=50 
| rex field=search "(?s)(NOT\s+index\s+[iI][nN]\s*\([^\)]+)|(index\s+[iI][nN]\s*\((?P<indexin>([^\)\"]+)|\"[^\)\"]+\"))" max_match=50 
| makemv delim="," indexin 
| eval indexes=mvappend(indexregex,indexin) 
| eval indexes=if(isnotnull(esstylewildcard),mvfilter(NOT match(indexes,"^_?\*$")),indexes) 
| eval wildcard=mvfilter(match(indexes,"\*")) 
| where isnotnull(wildcard) OR isnull(indexes) 
| eval short=mvmap(indexes,if(len(indexes)<=3,"True",null())) 
| eval short=if(isnull(short),"False","True") 
| search `comment("We now deal with cases where search earliest/latest times were not specified, assume all time is about 1 year in the past and latest time was the search run time")` 
| eval search_lt=if(search_lt=="N/A",_time,search_lt), search_et=if(search_et=="N/A",now()-(365*24*60*60),search_et) 
| eval period=search_lt-search_et 
| search `comment("Now that we have a giant list of indexes, we want to strip any quote characters and lowercase them in case we use a kvstore for lookups or similar.")` 
| search `comment("Run a lookup to find the default indexes and the allowed indexes per user")` 
| eval roles=replace(roles,"'","") 
| makemv roles delim="+" 
| lookup splunkadmins_indexes_per_role roles, splunk_server 
| fields indexes, user, period, total_run_time, event_count, scan_count, srchIndexesAllowed, srchIndexesDefault, search_id, search_et, search_lt, host, app_name, savedsearch_name, type, duration_command_search_index, duration_command_search_rawdata, invocations_command_search_index_bucketcache_hit, invocations_command_search_index_bucketcache_miss, duration_command_search_index_bucketcache_hit, duration_command_search_index_bucketcache_miss, invocations_command_search_rawdata_bucketcache_hit, invocations_command_search_rawdata_bucketcache_miss, duration_command_search_rawdata_bucketcache_hit, duration_command_search_rawdata_bucketcache_miss, short, _time 
| makemv srchIndexesAllowed tokenizer=(\S+) 
| streamfilterwildcard pattern=indexes fieldname=indexes srchIndexesAllowed 
| eval indexes=if(isnull(indexes),srchIndexesDefault,indexes) 
| eval indexes=mvmap(indexes, replace(lower(indexes), "\"", "")) 
| eval indexes=mvmap(indexes, trim(replace(indexes, "'", ""))) 
| makemv indexes tokenizer=(\S+) 
| eval search_head=host 
| eval search_head_cluster=`search_head_cluster` 
| eval indexes=mvdedup(indexes) 
| eval multi=if(mvcount(indexes)>1,"true","false") 
| stats values(_time) AS _time, values(total_run_time) AS total_run_time, values(event_count) AS event_count, values(scan_count) AS scan_count, values(search_et) AS search_et, values(search_lt) AS search_lt, values(savedsearch_name) AS savedsearch_name, values(multi) AS multi, max(duration_command_search_index) AS duration_index, max(duration_command_search_rawdata) AS duration_rawdata, max(invocations_command_search_index_bucketcache_hit) AS cache_index_hits, max(invocations_command_search_index_bucketcache_miss) AS cache_index_miss, max(duration_command_search_index_bucketcache_hit) AS cache_index_hit_duration, max(duration_command_search_index_bucketcache_miss) AS cache_index_miss_duration, max(invocations_command_search_rawdata_bucketcache_hit) AS cache_rawdata_hits, max(invocations_command_search_rawdata_bucketcache_miss) AS cache_rawdata_miss, max(duration_command_search_rawdata_bucketcache_hit) AS cache_rawdata_hit_duration, max(duration_command_search_rawdata_bucketcache_miss) AS cache_rawdata_miss_duration by user, type, search_id, indexes, search_head_cluster, app_name, short 
| eval period=search_lt-search_et 
| search `comment("Commands like multikv result in giant event count numbers compared to scan count, lower the lispy back down to normal to prevent the stats from been broken. lispy efficiency as per Martin Muller's conf presentations")` 
| eval lispy_efficiency = if(event_count>scan_count,scan_count,event_count) / scan_count
}
